{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optional-facial",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adapted-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optical-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immediate-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-screen",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concerned-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 384\n",
    "batch_size = 16 # 1080ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electoral-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-sperm",
   "metadata": {},
   "source": [
    "# Set-up BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "theoretical-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the slow pretrained tokenizer\n",
    "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "save_path = \"bert_base_uncased/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "slow_tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Load the fast tokenizer from saved file\n",
    "tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-glossary",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rolled-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
    "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
    "eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\n",
    "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-istanbul",
   "metadata": {},
   "source": [
    "# Data structure\n",
    "\n",
    "```bash\n",
    "train.json\n",
    "├── version\n",
    "└── data\n",
    "    ├── data[0]\n",
    "    │   ├── title\n",
    "    │   └── paragraphs\n",
    "    │       ├── paragraphs[0]\n",
    "    │       │   ├── context\n",
    "    │       │   └── qas\n",
    "    │       │       ├── qas[0]\n",
    "    │       │       │   ├── answers\n",
    "    │       │       │   │   ├── answers_start\n",
    "    │       │       │   │   └── text\n",
    "    │       │       │   ├── id\n",
    "    │       │       │   └── question\n",
    "    │       │       │   \n",
    "    │       │       │   ...\n",
    "    │       │       │   \n",
    "    │       │       └── qas[Q]\n",
    "    │       │       \n",
    "    │       │   ...    \n",
    "    │       │       \n",
    "    │       └── paragraphs[P]\n",
    "    │      \n",
    "    │   ...\n",
    "    │      \n",
    "    └── data[N]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "\n",
    "with open(eval_path) as f:\n",
    "    raw_eval_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expected-following",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.keras/datasets/train.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finnish-hygiene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [...], 'version': '1.1'}\n"
     ]
    }
   ],
   "source": [
    "pprint(raw_train_data, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "technical-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of title:  442\n"
     ]
    }
   ],
   "source": [
    "nb_data = len(raw_train_data['data'])\n",
    "print('The number of title: ',nb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "answering-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of paragraphs:  18896\n",
      "The average of the number of paragraphs:  42.75\n"
     ]
    }
   ],
   "source": [
    "nb_paragraphs = 0\n",
    "for i in range(nb_data):\n",
    "    nb_paragraphs += len(raw_train_data['data'][i]['paragraphs'])\n",
    "    \n",
    "print('The number of paragraphs: ',nb_paragraphs)\n",
    "print('The average of the number of paragraphs: ',np.around(nb_paragraphs / nb_data, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "experienced-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of questions:  87599\n",
      "The average of the number of paragraphs:  4.64\n"
     ]
    }
   ],
   "source": [
    "nb_questions = 0\n",
    "for i in range(nb_data):\n",
    "    for paragraph in raw_train_data['data'][i]['paragraphs']:\n",
    "        nb_questions += len(paragraph['qas'])\n",
    "\n",
    "print('The number of questions: ',nb_questions)\n",
    "print('The average of the number of paragraphs: ',np.around(nb_questions / nb_paragraphs, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-accessory",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cellular-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b455ca57dba54c7e93aed2e1d97d78d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='DATA', max=442.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4980 training points created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63d023284ae450a9370e2e790beac6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='DATA', max=48.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "627 evaluation points created.\n"
     ]
    }
   ],
   "source": [
    "class SquadExample:\n",
    "    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.all_answers = all_answers\n",
    "        self.skip = False\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        answer_text = self.answer_text\n",
    "        start_char_idx = self.start_char_idx\n",
    "\n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "        answer = \" \".join(str(answer_text).split())\n",
    "\n",
    "        # Find end character index of answer in context\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "        if end_char_idx >= len(context):\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Mark the character indexes in context that are in answer\n",
    "        is_char_in_ans = [0] * len(context)\n",
    "        for idx in range(start_char_idx, end_char_idx):\n",
    "            is_char_in_ans[idx] = 1\n",
    "\n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "\n",
    "        # Find tokens that were created from answer characters\n",
    "        ans_token_idx = []\n",
    "        for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "            if sum(is_char_in_ans[start:end]) > 0:\n",
    "                ans_token_idx.append(idx)\n",
    "\n",
    "        if len(ans_token_idx) == 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Find start and end token index for tokens from answer\n",
    "        start_token_idx = ans_token_idx[0]\n",
    "        end_token_idx = ans_token_idx[-1]\n",
    "\n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "\n",
    "        # Create inputs\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
    "            tokenized_question.ids[1:]\n",
    "        )\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Pad and create attention masks.\n",
    "        # Skip if truncation is needed\n",
    "        padding_length = max_len - len(input_ids)\n",
    "        if padding_length > 0:  # pad\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:  # skip\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.start_token_idx = start_token_idx\n",
    "        self.end_token_idx = end_token_idx\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "\n",
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in tqdm(raw_data[\"data\"], desc='DATA'):\n",
    "        for para in item[\"paragraphs\"][:2]: # sampling for fast training test\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
    "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                squad_eg = SquadExample(\n",
    "                    question, context, start_char_idx, answer_text, all_answers\n",
    "                )\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                # getattr(item, key) == item.input_ids\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "    x = [\n",
    "        dataset_dict[\"input_ids\"],\n",
    "        dataset_dict[\"token_type_ids\"],\n",
    "        dataset_dict[\"attention_mask\"],\n",
    "    ]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-prerequisite",
   "metadata": {},
   "source": [
    "Create the Question-Answering Model using BERT and Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-calibration",
   "metadata": {},
   "source": [
    "# Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regulated-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super(SquadDataset, self).__init__()        \n",
    "        self.input_ids_lst, self.token_type_ids_lst, self.attention_mask_lst = x_data\n",
    "        self.start_token_idx_lst, self.end_token_idx_lst = y_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids_lst)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = {\n",
    "            'input_ids':self.input_ids_lst[idx],\n",
    "            'token_type_ids':self.token_type_ids_lst[idx],\n",
    "            'attention_mask':self.attention_mask_lst[idx]\n",
    "        }\n",
    "        y = {\n",
    "            'start_token_idx':self.start_token_idx_lst[idx],\n",
    "            'end_token_idx':self.end_token_idx_lst[idx]\n",
    "        }\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stretch-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SquadDataset(x_data=x_train, y_data=y_train)\n",
    "validset = SquadDataset(x_data=x_eval, y_data=y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "proof-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(validset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-consciousness",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "diverse-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QABert(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QABert, self).__init__()\n",
    "        # Bert encoder\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        # start token layer\n",
    "        self.linear_start = torch.nn.Linear(in_features=self.bert.config.hidden_size, \n",
    "                                            out_features=1,\n",
    "                                            bias=False)\n",
    "        # end token layer\n",
    "        self.linear_end = torch.nn.Linear(in_features=self.bert.config.hidden_size, \n",
    "                                          out_features=1,\n",
    "                                          bias=False)\n",
    "        \n",
    "    def forward(self, \n",
    "                input_ids,\n",
    "                token_type_ids,\n",
    "                attention_mask):\n",
    "        embedding = self.bert(input_ids,\n",
    "                              token_type_ids=token_type_ids,\n",
    "                              attention_mask=attention_mask)\n",
    "        \n",
    "        start_output = self.linear_start(embedding[0]).squeeze()\n",
    "        end_output = self.linear_end(embedding[0]).squeeze()\n",
    "        \n",
    "        return start_output, end_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concrete-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QABert().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "remarkable-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model params - Pytorch model params\n",
      "109483776 - 109483776:  0\n"
     ]
    }
   ],
   "source": [
    "keras_model_nb_params = 109483776\n",
    "torch_model_nb_params = np.sum([np.prod(param.size()) for param in model.parameters()])\n",
    "print(f'Keras model params - Pytorch model params')\n",
    "print(f'{keras_model_nb_params} - {torch_model_nb_params}: ',\n",
    "      keras_model_nb_params - torch_model_nb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-insured",
   "metadata": {},
   "source": [
    "**[Keras] CateogicalCrossEntropy VS SparseCategoricalCrossEntropy**\n",
    "\n",
    "- 설명: https://ahnjg.tistory.com/88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ready-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuations\n",
    "    exclude = set(string.punctuation)\n",
    "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    # Remove articles\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    text = re.sub(regex, \" \", text)\n",
    "\n",
    "    # Remove extra white space\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "class ExactMatch(object):\n",
    "    def __init__(self, squad_examples=None):\n",
    "        self.squad_examples = [_ for _ in squad_examples if _.skip == False]\n",
    "        \n",
    "    def evaluate(self, start_preds, end_preds):\n",
    "        # ExactMatch\n",
    "        count = 0\n",
    "\n",
    "        for idx, (start, end) in enumerate(zip(start_preds, end_preds)):\n",
    "            squad_eg = self.squad_examples[idx]\n",
    "            pred_ans, true_ans = self._inference(start=start,\n",
    "                                                end=end,\n",
    "                                                squad_example=squad_eg)\n",
    "            if (pred_ans is None) or (true_ans is None):\n",
    "                continue\n",
    "                \n",
    "            if pred_ans in true_ans:\n",
    "                count += 1\n",
    "            \n",
    "        acc = count / len(start_preds)\n",
    "        print(f\"Exact Match Score={acc:.2%}\")\n",
    "        \n",
    "        \n",
    "    def _inference(self, start, end, squad_example):\n",
    "        return self.inference(start, end, squad_example)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def inference(start, end, squad_example):\n",
    "        offsets = squad_example.context_token_to_char\n",
    "        \n",
    "        # if answer start token index larger than offset length, then return None\n",
    "        if start >= len(offsets):\n",
    "            return None, None\n",
    "        \n",
    "        pred_char_start = offsets[start][0]\n",
    "\n",
    "        if end < len(offsets):\n",
    "            pred_char_end = offsets[end][1]\n",
    "            pred_ans = squad_example.context[pred_char_start:pred_char_end]\n",
    "        else:\n",
    "            pred_ans = squad_example.context[pred_char_start:]\n",
    "\n",
    "        normalized_pred_ans = normalize_text(pred_ans)\n",
    "        normalized_true_ans = [normalize_text(_) for _ in squad_example.all_answers]\n",
    "        \n",
    "        return normalized_pred_ans, normalized_true_ans\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "novel-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, batch_i in enumerate(dataloader):\n",
    "        # inputs and targets\n",
    "        input_ids = batch_i[0]['input_ids'].to(device)\n",
    "        attention_mask = batch_i[0]['attention_mask'].to(device)\n",
    "        token_type_ids = batch_i[0]['token_type_ids'].to(device)\n",
    "        start_targets = batch_i[1]['start_token_idx'].to(device)\n",
    "        end_targets = batch_i[1]['end_token_idx'].to(device)\n",
    "        \n",
    "        # reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # model output\n",
    "        start_outputs, end_outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        \n",
    "        # loss\n",
    "        start_loss = criterion(start_outputs, start_targets)\n",
    "        end_loss = criterion(end_outputs, end_targets)\n",
    "        loss = start_loss + end_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # update optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        # massage\n",
    "        progress_bar(current=batch_idx, \n",
    "                     total=len(dataloader),\n",
    "                     msg='Loss: %.3f' % (total_loss/(batch_idx + 1)),\n",
    "                     term_width=100,\n",
    "                     notebook=True)\n",
    "        \n",
    "\n",
    "# ExactMaching\n",
    "def validation(model, dataloader, criterion, device, exactmatch):\n",
    "    total_loss = 0\n",
    "    \n",
    "    total_start_preds, total_end_preds = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_i in enumerate(dataloader):\n",
    "            # inputs and targets\n",
    "            input_ids = batch_i[0]['input_ids'].to(device)\n",
    "            attention_mask = batch_i[0]['attention_mask'].to(device)\n",
    "            token_type_ids = batch_i[0]['token_type_ids'].to(device)\n",
    "            start_targets = batch_i[1]['start_token_idx'].to(device)\n",
    "            end_targets = batch_i[1]['end_token_idx'].to(device)\n",
    "\n",
    "            # model output\n",
    "            start_outputs, end_outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            \n",
    "            _, start_preds = start_outputs.max(1)\n",
    "            _, end_preds = end_outputs.max(1)\n",
    "            total_start_preds.extend(start_preds.cpu().numpy())\n",
    "            total_end_preds.extend(end_preds.cpu().numpy())\n",
    "            \n",
    "            # loss\n",
    "            start_loss = criterion(start_outputs, start_targets)\n",
    "            end_loss = criterion(end_outputs, end_targets)\n",
    "            loss = start_loss + end_loss\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # massage\n",
    "            progress_bar(current=batch_idx, \n",
    "                         total=len(dataloader),\n",
    "                         msg='Loss: %.3f' % (total_loss/(batch_idx + 1)),\n",
    "                         term_width=100,\n",
    "                         notebook=True)\n",
    "            \n",
    "        exactmatch.evaluate(start_preds=total_start_preds,\n",
    "                            end_preds=total_end_preds)\n",
    "\n",
    "\n",
    "            \n",
    "def fit(model, epochs, trainloader, criterion, optimizer, device, validloader=None, eval_squad_examples=None):\n",
    "    for epoch in range(epochs):\n",
    "        print('Fit start')\n",
    "        print(f'\\nEpochs: {epoch+1}/{epochs}')\n",
    "        train(model, trainloader, criterion, optimizer, device)\n",
    "        if validloader is not None:\n",
    "            eval_exactmatch = ExactMatch(squad_examples=eval_squad_examples)\n",
    "            validation(model, validloader, criterion, device, eval_exactmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hispanic-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "motivated-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit(model=model,\n",
    "#     epochs=1,\n",
    "#     trainloader=trainloader,\n",
    "#     validloader=validloader,\n",
    "#     criterion=criterion,\n",
    "#     optimizer=optimizer,\n",
    "#     device=device,\n",
    "#     eval_squad_examples=eval_squad_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-basics",
   "metadata": {},
   "source": [
    "# Inference Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coordinate-hollow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_info = torch.load('./Text_Extraction_with_BERT/QABert.pth')\n",
    "model.load_state_dict(save_info['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "interstate-anaheim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predict Answer]\n",
      "50 was american football game to determine champion of national football league nfl for 2015 season american football conference afc champion denver broncos defeated national football conference nfc champion carolina panthers 24–10 to earn their third super bowl title game was played on february 7 2016 at levis stadium in san francisco bay area at santa clara california as this was 50th super bowl league emphasized golden anniversary\n",
      "\n",
      "[True Answer]\n",
      "- Asnwer0: denver broncos\n",
      "- Asnwer1: denver broncos\n",
      "- Asnwer2: denver broncos\n"
     ]
    }
   ],
   "source": [
    "# sample index\n",
    "sample_idx = 0\n",
    "sample_input_ids = torch.LongTensor(x_eval[0][[sample_idx]])\n",
    "sample_token_type_ids = torch.LongTensor(x_eval[1][[sample_idx]])\n",
    "sample_attention_mask = torch.LongTensor(x_eval[2][[sample_idx]])\n",
    "\n",
    "# predict start and end index\n",
    "start, end = model(sample_input_ids.to(device),\n",
    "                   sample_token_type_ids.to(device),\n",
    "                   sample_attention_mask.to(device))\n",
    "\n",
    "_, start = start.unsqueeze(0).max(1)\n",
    "_, end = end.unsqueeze(0).max(1)\n",
    "\n",
    "# inference predict answer\n",
    "eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "\n",
    "pred_ans, true_ans = ExactMatch.inference(start=start,\n",
    "                                          end=end,\n",
    "                                          squad_example=eval_examples_no_skip[sample_idx])\n",
    "\n",
    "print('[Predict Answer]')\n",
    "print(pred_ans)\n",
    "print()\n",
    "print('[True Answer]')\n",
    "for idx, ans in enumerate(true_ans):\n",
    "    print(f'- Asnwer{idx}: {ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "focused-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predict Answer]\n",
      "50 was american football game to determine champion of national football league nfl for 2015 season american football conference afc champion denver broncos defeated national football conference nfc champion carolina panthers 24–10 to earn their third super bowl title game was played on february 7 2016 at levis stadium in san francisco bay area at santa clara california as this was 50th super bowl league emphasized golden anniversary\n",
      "\n",
      "[True Answer]\n",
      "- Asnwer0: denver broncos\n",
      "- Asnwer1: denver broncos\n",
      "- Asnwer2: denver broncos\n"
     ]
    }
   ],
   "source": [
    "# sample index\n",
    "sample_idx = 0\n",
    "sample_input_ids = torch.LongTensor(x_eval[0][[sample_idx]])\n",
    "sample_token_type_ids = torch.LongTensor(x_eval[1][[sample_idx]])\n",
    "sample_attention_mask = torch.LongTensor(x_eval[2][[sample_idx]])\n",
    "\n",
    "# predict start and end index\n",
    "start, end = model(sample_input_ids.to(device),\n",
    "                   sample_token_type_ids.to(device),\n",
    "                   sample_attention_mask.to(device))\n",
    "\n",
    "_, start = start.unsqueeze(0).max(1)\n",
    "_, end = end.unsqueeze(0).max(1)\n",
    "\n",
    "# inference predict answer\n",
    "eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "\n",
    "pred_ans, true_ans = ExactMatch.inference(start=start,\n",
    "                                          end=end,\n",
    "                                          squad_example=eval_examples_no_skip[sample_idx])\n",
    "\n",
    "print('[Predict Answer]')\n",
    "print(pred_ans)\n",
    "print()\n",
    "print('[True Answer]')\n",
    "for idx, ans in enumerate(true_ans):\n",
    "    print(f'- Asnwer{idx}: {ans}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
