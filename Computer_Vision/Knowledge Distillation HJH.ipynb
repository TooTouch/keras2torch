{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0, 0.5),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Teacher, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.leakyrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2) # padding 'same' do not exit...\n",
    "        \n",
    "        self.dense = torch.nn.Linear(4*4*512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.leakyrelu(output)\n",
    "        output = self.max_pool(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.dense(output.view(output.size(0), -1))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class Student(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Student, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.leakyrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2) # padding 'same' do not exit...\n",
    "        \n",
    "        self.dense = torch.nn.Linear(4*4*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.leakyrelu(output)\n",
    "        output = self.max_pool(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.dense(output.view(output.size(0), -1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = Teacher().to(device)\n",
    "student = Student().to(device)\n",
    "student_scratch = Student().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_opt = torch.optim.Adam(teacher.parameters(), lr=0.001)\n",
    "student_opt = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "student_scratch_opt = torch.optim.Adam(student_scratch.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "distill_criterion = torch.nn.KLDivLoss(reduction='batchmean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Pytorch KL-Divergence 실험 (feat. log_softmax와 softmax 무엇이 맞는지)\n",
    "- https://douglasrizzo.com.br/kl-div-pytorch/\n",
    "\n",
    "<div align='center'>\n",
    "    <img width=\"400\" src=\"https://www.oreilly.com/library/view/generative-adversarial-networks/9781789136678/assets/3ed12abb-fb0d-4205-848a-928127ec92ca.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, dataloader, criterion, optimizer, teacher_model=None, \n",
    "    distill_criterion=None, alpha=0.1, temperature=10, device='cpu'\n",
    "):\n",
    "    if teacher_model!=None:\n",
    "        teacher_model.eval()\n",
    "        \n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    for idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # predict\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if teacher_model != None:\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            \n",
    "        # loss and update\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        if teacher_model != None:\n",
    "            student_outputs = torch.nn.functional.log_softmax(outputs / temperature, dim=1) # log softmax\n",
    "            teacher_outputs = torch.nn.functional.softmax(teacher_outputs / temperature, dim=1) # softmax\n",
    "            \n",
    "            distill_loss = distill_criterion(student_outputs, teacher_outputs)\n",
    "            \n",
    "            loss = alpha * loss + (1 - alpha) * distill_loss \n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # total loss and acc\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds = outputs.argmax(dim=1) \n",
    "        correct += targets.eq(preds).sum().item()\n",
    "        total += targets.size(0)\n",
    "        \n",
    "        if idx == (len(dataloader)-1):\n",
    "            print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                  (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\n')\n",
    "        else:\n",
    "            print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                  (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\r')\n",
    "        \n",
    "        \n",
    "def test(model, dataloader, criterion, device='cpu'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # predict\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # loss \n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # total loss and acc\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += targets.eq(preds).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "            \n",
    "            if idx == (len(dataloader)-1):\n",
    "                print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                      (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\n')\n",
    "            else:\n",
    "                print('[%d/%d]: Loss: %.3f | Acc: %.3f%% [%d/%d]' % \n",
    "                      (idx+1, len(dataloader), total_loss/(idx+1), 100.*correct/total, correct, total),end='\\r')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "[938/938]: Loss: 0.175 | Acc: 94.737% [56842/60000]\n",
      "[157/157]: Loss: 0.097 | Acc: 96.890% [9689/10000]\n",
      "Epoch: 2/5\n",
      "[938/938]: Loss: 0.098 | Acc: 97.027% [58216/60000]\n",
      "[157/157]: Loss: 0.075 | Acc: 97.570% [9757/10000]\n",
      "Epoch: 3/5\n",
      "[938/938]: Loss: 0.080 | Acc: 97.602% [58561/60000]\n",
      "[157/157]: Loss: 0.104 | Acc: 96.870% [9687/10000]\n",
      "Epoch: 4/5\n",
      "[938/938]: Loss: 0.071 | Acc: 97.805% [58683/60000]\n",
      "[157/157]: Loss: 0.097 | Acc: 97.350% [9735/10000]\n",
      "Epoch: 5/5\n",
      "[938/938]: Loss: 0.067 | Acc: 98.065% [58839/60000]\n",
      "[157/157]: Loss: 0.107 | Acc: 97.160% [9716/10000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train(teacher, trainloader, criterion, teacher_opt, device=device)\n",
    "    test(teacher, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "[938/938]: Loss: 0.168 | Acc: 87.383% [52430/60000]\n",
      "[157/157]: Loss: 0.197 | Acc: 95.000% [9500/10000]\n",
      "Epoch: 2/3\n",
      "[938/938]: Loss: 0.057 | Acc: 95.397% [57238/60000]\n",
      "[157/157]: Loss: 0.131 | Acc: 96.550% [9655/10000]\n",
      "Epoch: 3/3\n",
      "[938/938]: Loss: 0.042 | Acc: 96.530% [57918/60000]\n",
      "[157/157]: Loss: 0.105 | Acc: 97.200% [9720/10000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train(student, trainloader, criterion, student_opt,\n",
    "          teacher, distill_criterion, alpha=0.1, temperature=10, device=device)\n",
    "    test(student, testloader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Scratch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "[938/938]: Loss: 0.387 | Acc: 88.713% [53228/60000]\n",
      "[157/157]: Loss: 0.163 | Acc: 95.100% [9510/10000]\n",
      "Epoch: 2/3\n",
      "[938/938]: Loss: 0.143 | Acc: 95.658% [57395/60000]\n",
      "[157/157]: Loss: 0.107 | Acc: 96.720% [9672/10000]\n",
      "Epoch: 3/3\n",
      "[938/938]: Loss: 0.111 | Acc: 96.578% [57947/60000]\n",
      "[157/157]: Loss: 0.096 | Acc: 96.880% [9688/10000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train(student_scratch, trainloader, criterion, student_scratch_opt, device=device)\n",
    "    test(student_scratch, testloader, criterion, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
