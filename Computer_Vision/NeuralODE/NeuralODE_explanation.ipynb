{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural ODE\n",
    "\n",
    "- reference\n",
    "    - paper : https://arxiv.org/abs/1806.07366\n",
    "    - code : https://github.com/rtqichen/torchdiffeq\n",
    "    - FAQ : https://github.com/rtqichen/torchdiffeq/blob/master/FAQ.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code structure\n",
    "- Author's code(torchdiffeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "torchdiffeq\n",
    "|\n",
    "├── README.md\n",
    "├── assets\n",
    "│   ├── bouncing_ball.png\n",
    "│   ├── cnf_demo.gif\n",
    "│   ├── ode_demo.gif\n",
    "│   ├── odenet_0_viz.png\n",
    "│   └── resnet_0_viz.png\n",
    "├── examples\n",
    "│   ├── README.md\n",
    "│   ├── bouncing_ball.py\n",
    "│   ├── cnf.py\n",
    "│   ├── latent_ode.py\n",
    "│   ├── ode_demo.py\n",
    "│   ├── odenet_mnist.py        *python script for MNIST classification\n",
    "├── setup.py\n",
    "├── tests\n",
    "├── torchdiffeq\n",
    "│   ├── __init__.py\n",
    "│   └── _impl\n",
    "│       ├── __init__.py\n",
    "│       ├── adaptive_heun.py    \n",
    "│       ├── adjoint.py           \n",
    "│       ├── bosh3.py               \n",
    "│       ├── dopri5.py\n",
    "│       ├── dopri8.py\n",
    "│       ├── event_handling.py\n",
    "│       ├── fehlberg2.py\n",
    "│       ├── fixed_adams.py\n",
    "│       ├── fixed_grid.py\n",
    "│       ├── interp.py\n",
    "│       ├── misc.py\n",
    "│       ├── odeint.py\n",
    "│       ├── rk_common.py\n",
    "│       ├── scipy_wrapper.py\n",
    "│       └── solvers.py\n",
    "└── tree_torchdiffeq.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example : MNIST digit image data classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](figures/acc_plots_normal_backprop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NFE plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](figures/nfe_plots_normal_backprop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjoint Sensitivity Method backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](figures/adj_acc_plots_adjoint_backward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NFE plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](figures/adj_nfe_plots_adjoint_backward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특이사항\n",
    "\n",
    "1. ODEFunc : nn.Module의 neural net\n",
    "    - 학습해야하는 함수가 size가 커지면, 그에 맞춰 parameter 갯수도 많아진다.\n",
    "    - 대신, forward 시(odeint), ctx.save_for_backward 안함..? 저장 안함?\n",
    "2. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main code for experiment\n",
    "```\n",
    "\n",
    "odenet_mnist.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[Process of Neural ODE in MNIST classification]\n",
    "\n",
    "1. Define downsampling method\n",
    "2. Define feature layers\n",
    "3. Define fc layers\n",
    "    - norm, relu, avgPooling, Flatten, nn.Linear(64,10)\n",
    "4. Define model\n",
    "    - downsampling layers - feature layers - fc layers\n",
    "5. Define others\n",
    "    - Loss function\n",
    "    - Optimizer\n",
    "6. train, validation, test  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 208266\n",
      "Epoch 0000 | Time 0.225 (0.225) | NFE-F 26.0 | NFE-B 0.0 | Train Acc 0.1124 | Test Acc 0.1135\n",
      "Epoch 0001 | Time 0.408 (0.289) | NFE-F 20.5 | NFE-B 0.0 | Train Acc 0.9775 | Test Acc 0.9796\n",
      "Epoch 0003 | Time 0.198 (0.134) | NFE-F 20.2 | NFE-B 0.0 | Train Acc 0.9905 | Test Acc 0.9900\n",
      "Epoch 0004 | Time 0.211 (0.132) | NFE-F 20.2 | NFE-B 0.0 | Train Acc 0.9919 | Test Acc 0.9919\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fc8f6300947c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fc8f6300947c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modefunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/DSBA/1. seminar/neural_ode/example/torchdiffeq/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/DSBA/1. seminar/neural_ode/example/torchdiffeq/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/DSBA/1. seminar/neural_ode/example/torchdiffeq/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/DSBA/1. seminar/neural_ode/example/torchdiffeq/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# trigger both. (i.e. interleaving them would be wrong.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runge_kutta_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtableau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# dtypes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# y1.dtype == self.y0.dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/DSBA/1. seminar/neural_ode/example/torchdiffeq/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UncheckedAssign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtableau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0malpha_i\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Always step to perturbing just before the end time, in case of discontinuities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet')\n",
    "parser.add_argument('--tol', type=float, default=1e-3)\n",
    "parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--downsampling-method', type=str, default='conv', choices=['conv', 'res'])\n",
    "parser.add_argument('--nepochs', type=int, default=160)\n",
    "parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False])\n",
    "parser.add_argument('--lr', type=float, default=0.1)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--test_batch_size', type=int, default=1000)\n",
    "parser.add_argument('--save', type=str, default='./experiment1')\n",
    "parser.add_argument('--debug', action='store_true')\n",
    "parser.add_argument('--gpu', type=int, default=0)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# Define backpropagation method : adjoint sensitivity method or Normal backpropagation\n",
    "if args.adjoint:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "# Other functions to utilize on this notebook\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "def norm(dim):\n",
    "    return nn.GroupNorm(min(32, dim), dim)\n",
    "\n",
    "\n",
    "# Residual block\n",
    "class ResBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.norm1 = norm(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.norm2 = norm(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "\n",
    "        out = self.relu(self.norm1(x))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(out)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "# Convolution layers : concat time step and data for ODEfunc\n",
    "class ConcatConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True, transpose=False):\n",
    "        super(ConcatConv2d, self).__init__()\n",
    "        module = nn.ConvTranspose2d if transpose else nn.Conv2d\n",
    "        self._layer = module(\n",
    "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        tt = torch.ones_like(x[:, :1, :, :]) * t\n",
    "        ttx = torch.cat([tt, x], 1)\n",
    "        return self._layer(ttx)\n",
    "\n",
    "# ODE function : imitate the structure of ResBlock\n",
    "class ODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(ODEfunc, self).__init__()\n",
    "        self.norm1 = norm(dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm2 = norm(dim)\n",
    "        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm3 = norm(dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.norm1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(t, out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(t, out)\n",
    "        out = self.norm3(out)\n",
    "        return out\n",
    "       \n",
    "# ODE Block : Just run ODE solver(\"odeint\")\n",
    "class ODEBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, odefunc):\n",
    "        super(ODEBlock, self).__init__()\n",
    "        self.odefunc = odefunc\n",
    "        self.integration_time = torch.tensor([0, 1]).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.integration_time = self.integration_time.type_as(x)\n",
    "        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)\n",
    "        return out[1]\n",
    "\n",
    "    # @nfe.setter : attribute 값 저장하는 method\n",
    "    # reference : https://dojang.io/mod/page/view.php?id=2476\n",
    "    @property\n",
    "    def nfe(self):\n",
    "        return self.odefunc.nfe\n",
    "\n",
    "    @nfe.setter\n",
    "    def nfe(self, value):\n",
    "        self.odefunc.nfe = value\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, shape)\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "def get_mnist_loaders(data_aug=False, batch_size=128, test_batch_size=1000, perc=1.0):\n",
    "    if data_aug:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(28, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    else:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_train), batch_size=batch_size,\n",
    "        shuffle=True, num_workers=2, drop_last=True\n",
    "    )\n",
    "\n",
    "    train_eval_loader = DataLoader(\n",
    "        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_test),\n",
    "        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(root='.data/mnist', train=False, download=True, transform=transform_test),\n",
    "        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader, train_eval_loader\n",
    "\n",
    "def inf_generator(iterable):\n",
    "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
    "        for i, (x, y) in enumerate(inf_generator(train_loader)):\n",
    "    \"\"\"\n",
    "    iterator = iterable.__iter__()\n",
    "    while True:\n",
    "        try:\n",
    "            yield iterator.__next__()\n",
    "        except StopIteration:\n",
    "            iterator = iterable.__iter__()\n",
    "\n",
    "def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):\n",
    "    initial_learning_rate = args.lr * batch_size / batch_denom\n",
    "\n",
    "    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]\n",
    "    vals = [initial_learning_rate * decay for decay in decay_rates]\n",
    "\n",
    "    def learning_rate_fn(itr):\n",
    "        lt = [itr < b for b in boundaries] + [True]\n",
    "        i = np.argmax(lt)\n",
    "        return vals[i]\n",
    "\n",
    "    return learning_rate_fn\n",
    "\n",
    "def one_hot(x, K):\n",
    "    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\n",
    "\n",
    "def accuracy(model, dataset_loader):\n",
    "    total_correct = 0\n",
    "    for x, y in dataset_loader:\n",
    "        x = x.to(device)\n",
    "        y = one_hot(np.array(y.numpy()), 10)\n",
    "\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1)\n",
    "        total_correct += np.sum(predicted_class == target_class)\n",
    "    return total_correct / len(dataset_loader.dataset)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def makedirs(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "\n",
    "makedirs(args.save)\n",
    "device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set network structure : ODENet or ResNet\n",
    "is_odenet = args.network == 'odenet'\n",
    "\n",
    "# Set downsampling method : Convolution or Residual block\n",
    "if args.downsampling_method == 'conv':\n",
    "    downsampling_layers = [\n",
    "        nn.Conv2d(1, 64, 3, 1),\n",
    "        norm(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 64, 4, 2, 1),\n",
    "        norm(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 64, 4, 2, 1),\n",
    "    ]\n",
    "elif args.downsampling_method == 'res':\n",
    "    downsampling_layers = [\n",
    "        nn.Conv2d(1, 64, 3, 1),\n",
    "        ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)), # downsample argument = 1x1 conv downsampling for shortcut\n",
    "        ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)), # downsample argument = 1x1 conv downsampling for shortcut\n",
    "    ]\n",
    "\n",
    "# ODEBlock은 ODEFunc(64)로 한번 미분방정식 세팅해 feature layers 형성\n",
    "# ResBlock은 6번의 ResBlock을 반복해 feature layers 형성\n",
    "feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\n",
    "fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\n",
    "\n",
    "# Define model structure\n",
    "model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n",
    "\n",
    "print('Number of parameters: {}'.format(count_parameters(model)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "train_loader, test_loader, train_eval_loader = get_mnist_loaders(\n",
    "    args.data_aug, args.batch_size, args.test_batch_size\n",
    ")\n",
    "\n",
    "data_gen = inf_generator(train_loader)\n",
    "batches_per_epoch = len(train_loader)\n",
    "\n",
    "lr_fn = learning_rate_with_decay(\n",
    "    args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],\n",
    "    decay_rates=[1, 0.1, 0.01, 0.001]\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "\n",
    "best_acc = 0\n",
    "batch_time_meter = RunningAverageMeter()\n",
    "f_nfe_meter = RunningAverageMeter()\n",
    "b_nfe_meter = RunningAverageMeter()\n",
    "end = time.time()\n",
    "\n",
    "for itr in range(args.nepochs * batches_per_epoch):\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr_fn(itr)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    x, y = data_gen.__next__()\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    logits = model(x)\n",
    "    loss = criterion(logits, y)\n",
    "\n",
    "    # forward에서 NFE 초기화 (property - setter 활용)\n",
    "    if is_odenet:\n",
    "        nfe_forward = feature_layers[0].nfe\n",
    "        feature_layers[0].nfe = 0\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # backward에서 NFE 초기화 (property - setter 활용)\n",
    "    if is_odenet:\n",
    "        nfe_backward = feature_layers[0].nfe\n",
    "        feature_layers[0].nfe = 0\n",
    "\n",
    "    # 각 batch마다 NFE 누적 (update)\n",
    "    batch_time_meter.update(time.time() - end)\n",
    "    if is_odenet:\n",
    "        f_nfe_meter.update(nfe_forward)\n",
    "        b_nfe_meter.update(nfe_backward)\n",
    "    end = time.time()\n",
    "\n",
    "    if itr % batches_per_epoch == 0:\n",
    "        with torch.no_grad():\n",
    "            train_acc = accuracy(model, train_eval_loader)\n",
    "            val_acc = accuracy(model, test_loader)\n",
    "            if val_acc > best_acc:\n",
    "                torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))\n",
    "                best_acc = val_acc\n",
    "                \n",
    "                print(\"Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | \"\n",
    "                \"Train Acc {:.4f} | Test Acc {:.4f}\".format(\n",
    "                    itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,\n",
    "                    b_nfe_meter.avg, train_acc, val_acc\n",
    "                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[model structure of ODEnet]**\n",
    "\n",
    "```\n",
    "\n",
    "Number of parameters: 232,970\n",
    "\n",
    "Sequential(                         \n",
    "\n",
    "  #==================================down sampling==================================#\n",
    "\n",
    "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
    "  (1): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (downsample): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  (2): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (downsample): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  \n",
    "  #==================================feature layer==================================#\n",
    "  \n",
    "  (3): ODEBlock(\n",
    "    (odefunc): ODEfunc(\n",
    "      (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv1): ConcatConv2d(\n",
    "        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      )\n",
    "      (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "      (conv2): ConcatConv2d(\n",
    "        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      )\n",
    "      (norm3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    )\n",
    "  )\n",
    "  \n",
    "  #==================================fc layer=======================================#\n",
    "  \n",
    "  (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "  (5): ReLU(inplace=True)\n",
    "  (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (7): Flatten()\n",
    "  (8): Linear(in_features=64, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[model structure of ResNet]**\n",
    "\n",
    "```\n",
    "\n",
    "Number of parameters: 576,778 (Neural ODE : 232,970)\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
    "  (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "  (2): ReLU(inplace=True)\n",
    "  (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
    "  (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "  (5): ReLU(inplace=True)\n",
    "  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
    "  (7): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  (8): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  (9): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  (10): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  (11): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  (12): ResBlock(\n",
    "    (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "  )\n",
    "  (13): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
    "  (14): ReLU(inplace=True)\n",
    "  (15): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (16): Flatten()\n",
    "  (17): Linear(in_features=64, out_features=10, bias=True)\n",
    ")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code for ODEBlock\n",
    "```\n",
    "\n",
    "odeint.py\n",
    "\n",
    "    - We use this script when we do not use Adjoint Sensitivity Method\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import torch\n",
    "from torch.autograd.functional import vjp \n",
    "# from torch.autograd.functional import vjp : Function that computes the dot product between a vector v and the Jacobian of the given function at the point given by the inputs.\n",
    "# reference : https://pytorch.org/docs/stable/generated/torch.autograd.functional.vjp.html\n",
    "# reference 2 : https://runebook.dev/ko/docs/pytorch/autograd\n",
    "from .dopri5 import Dopri5Solver\n",
    "from .bosh3 import Bosh3Solver\n",
    "from .adaptive_heun import AdaptiveHeunSolver\n",
    "from .fehlberg2 import Fehlberg2\n",
    "from .fixed_grid import Euler, Midpoint, RK4\n",
    "from .fixed_adams import AdamsBashforth, AdamsBashforthMoulton\n",
    "from .dopri8 import Dopri8Solver\n",
    "from .scipy_wrapper import ScipyWrapperODESolver\n",
    "from .misc import _check_inputs, _flat_to_shape\n",
    "\n",
    "SOLVERS = {\n",
    "    'dopri8': Dopri8Solver,\n",
    "    'dopri5': Dopri5Solver,  # default (Adaptive step size)\n",
    "    'bosh3': Bosh3Solver,\n",
    "    'fehlberg2': Fehlberg2,\n",
    "    'adaptive_heun': AdaptiveHeunSolver,\n",
    "    'euler': Euler,\n",
    "    'midpoint': Midpoint,\n",
    "    'rk4': RK4,\n",
    "    'explicit_adams': AdamsBashforth,\n",
    "    'implicit_adams': AdamsBashforthMoulton,\n",
    "    # Backward compatibility: use the same name as before\n",
    "    'fixed_adams': AdamsBashforthMoulton,\n",
    "    # ~Backwards compatibility\n",
    "    'scipy_solver': ScipyWrapperODESolver,\n",
    "}\n",
    "\n",
    "\n",
    "def odeint(func, y0, t, *, rtol=1e-7, atol=1e-9, method=None, options=None, event_fn=None):\n",
    "    \"\"\"Integrate a system of ordinary differential equations.\n",
    "\n",
    "    Solves the initial value problem for a non-stiff system of first order ODEs:\n",
    "        ```\n",
    "        dy/dt = func(t, y), y(t[0]) = y0\n",
    "        ```\n",
    "    where y is a Tensor or tuple of Tensors of any shape.\n",
    "\n",
    "    Output dtypes and numerical precision are based on the dtypes of the inputs `y0`.\n",
    "\n",
    "    Args:\n",
    "        func: Function that maps a scalar Tensor `t` and a Tensor holding the state `y`\n",
    "            into a Tensor of state derivatives with respect to time. Optionally, `y`\n",
    "            can also be a tuple of Tensors.\n",
    "        y0: N-D Tensor giving starting value of `y` at time point `t[0]`. Optionally, `y0`\n",
    "            can also be a tuple of Tensors.\n",
    "        t: 1-D Tensor holding a sequence of time points for which to solve for\n",
    "            `y`, in either increasing or decreasing order. The first element of\n",
    "            this sequence is taken to be the initial time point.\n",
    "        rtol: optional float64 Tensor specifying an upper bound on relative error,\n",
    "            per element of `y`.\n",
    "        atol: optional float64 Tensor specifying an upper bound on absolute error,\n",
    "            per element of `y`.\n",
    "        method: optional string indicating the integration method to use.\n",
    "        options: optional dict of configuring options for the indicated integration\n",
    "            method. Can only be provided if a `method` is explicitly set.\n",
    "        event_fn: Function that maps the state `y` to a Tensor. The solve terminates when\n",
    "            event_fn evaluates to zero. If this is not None, all but the first elements of\n",
    "            `t` are ignored.\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor, where the first dimension corresponds to different\n",
    "            time points. Contains the solved value of y for each desired time point in\n",
    "            `t`, with the initial value `y0` being the first element along the first\n",
    "            dimension.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if an invalid `method` is provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # _check_inputs : has a lot of 'assert' series! -> check input's type, etc..\n",
    "    # Also, Here, We set 'ode solver name(method)' (default : dopri5)\n",
    "    shapes, func, y0, t, rtol, atol, method, options, event_fn, t_is_reversed = _check_inputs(func, y0, t, rtol, atol, method, options, event_fn, SOLVERS)\n",
    "\n",
    "    # Set ode Solver\n",
    "    # This initiation comes from 'rk_common.py - RKAdaptiveStepsizeODESolver'\n",
    "    solver = SOLVERS[method](func=func, y0=y0, rtol=rtol, atol=atol, **options)\n",
    "\n",
    "    if event_fn is None:\n",
    "        solution = solver.integrate(t)\n",
    "    else:\n",
    "        event_t, solution = solver.integrate_until_event(t[0], event_fn)\n",
    "        event_t = event_t.to(t)\n",
    "        if t_is_reversed:\n",
    "            event_t = -event_t\n",
    "\n",
    "    if shapes is not None:\n",
    "        solution = _flat_to_shape(solution, (len(t),), shapes)\n",
    "\n",
    "    # get the solution!\n",
    "    if event_fn is None:\n",
    "        return solution\n",
    "    else:\n",
    "        return event_t, solution\n",
    "\n",
    "\n",
    "def odeint_event(func, y0, t0, *, event_fn, reverse_time=False, odeint_interface=odeint, **kwargs):\n",
    "    \"\"\"Automatically links up the gradient from the event time.\"\"\"\n",
    "\n",
    "    if reverse_time:\n",
    "        t = torch.cat([t0.reshape(-1), t0.reshape(-1).detach() - 1.0])\n",
    "    else:\n",
    "        t = torch.cat([t0.reshape(-1), t0.reshape(-1).detach() + 1.0])\n",
    "\n",
    "    event_t, solution = odeint_interface(func, y0, t, event_fn=event_fn, **kwargs)\n",
    "\n",
    "    # Dummy values for rtol, atol, method, and options.\n",
    "    shapes, _func, _, t, _, _, _, _, event_fn, _ = _check_inputs(func, y0, t, 0.0, 0.0, None, None, event_fn, SOLVERS)\n",
    "\n",
    "    if shapes is not None:\n",
    "        state_t = torch.cat([s[-1].reshape(-1) for s in solution])\n",
    "    else:\n",
    "        state_t = solution[-1]\n",
    "\n",
    "    # Event_fn takes in negated time value if reverse_time is True.\n",
    "    if reverse_time:\n",
    "        event_t = -event_t\n",
    "\n",
    "    event_t, state_t = ImplicitFnGradientRerouting.apply(_func, event_fn, event_t, state_t)\n",
    "\n",
    "    # Return the user expected time value.\n",
    "    if reverse_time:\n",
    "        event_t = -event_t\n",
    "\n",
    "    if shapes is not None:\n",
    "        state_t = _flat_to_shape(state_t, (), shapes)\n",
    "        solution = tuple(torch.cat([s[:-1], s_t[None]], dim=0) for s, s_t in zip(solution, state_t))\n",
    "    else:\n",
    "        solution = torch.cat([solution[:-1], state_t[None]], dim=0)\n",
    "\n",
    "    return event_t, solution\n",
    "\n",
    "\n",
    "class ImplicitFnGradientRerouting(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, func, event_fn, event_t, state_t):\n",
    "        \"\"\" event_t is the solution to event_fn \"\"\"\n",
    "        ctx.func = func\n",
    "        ctx.event_fn = event_fn\n",
    "        ctx.save_for_backward(event_t, state_t)\n",
    "        return event_t.detach(), state_t.detach()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_t, grad_state):\n",
    "        func = ctx.func\n",
    "        event_fn = ctx.event_fn\n",
    "        event_t, state_t = ctx.saved_tensors\n",
    "\n",
    "        event_t = event_t.detach().clone().requires_grad_(True)\n",
    "        state_t = state_t.detach().clone().requires_grad_(True)\n",
    "\n",
    "        f_val = func(event_t, state_t)\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            c, (par_dt, dstate) = vjp(event_fn, (event_t, state_t))\n",
    "\n",
    "        # Total derivative of event_fn wrt t evaluated at event_t.\n",
    "        dcdt = par_dt + torch.sum(dstate * f_val)\n",
    "\n",
    "        # Add the gradient from final state to final time value as if a regular odeint was called.\n",
    "        grad_t = grad_t + torch.sum(grad_state * f_val)\n",
    "\n",
    "        dstate = dstate * (-grad_t / (dcdt + 1e-12)).reshape_as(c)\n",
    "\n",
    "        grad_state = grad_state + dstate\n",
    "\n",
    "        return None, None, None, grad_state\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code for ODEBlock (2)\n",
    "```\n",
    "\n",
    "adjoint.py\n",
    "\n",
    "    - We use this script when we use Adjoint Sensitivity Method\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from .odeint import SOLVERS, odeint\n",
    "from .misc import _check_inputs, _flat_to_shape\n",
    "from .misc import _mixed_norm\n",
    "\n",
    "\n",
    "class OdeintAdjointMethod(torch.autograd.Function):\n",
    "\n",
    "    # ctx는 역전파 연산을 위한 정보를 저장하기 위해 사용하는 Context Object\n",
    "    @staticmethod\n",
    "    def forward(ctx, shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, t_requires_grad, *adjoint_params):\n",
    "\n",
    "        ctx.shapes = shapes\n",
    "        ctx.func = func\n",
    "        ctx.adjoint_rtol = adjoint_rtol\n",
    "        ctx.adjoint_atol = adjoint_atol\n",
    "        ctx.adjoint_method = adjoint_method\n",
    "        ctx.adjoint_options = adjoint_options\n",
    "        ctx.t_requires_grad = t_requires_grad\n",
    "        ctx.event_mode = event_fn is not None\n",
    "        \n",
    "        # forward : odeint (ode solver forward)\n",
    "        with torch.no_grad():\n",
    "            ans = odeint(func, y0, t, rtol=rtol, atol=atol, method=method, options=options, event_fn=event_fn)\n",
    "\n",
    "            if event_fn is None:\n",
    "                y = ans\n",
    "            else:\n",
    "                event_t, y = ans\n",
    "                ctx.event_t = event_t\n",
    "\n",
    "        \n",
    "        ctx.save_for_backward(t, y, *adjoint_params)\n",
    "        return ans\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grad_y):\n",
    "        with torch.no_grad():\n",
    "            func = ctx.func\n",
    "            adjoint_rtol = ctx.adjoint_rtol\n",
    "            adjoint_atol = ctx.adjoint_atol\n",
    "            adjoint_method = ctx.adjoint_method\n",
    "            adjoint_options = ctx.adjoint_options\n",
    "            t_requires_grad = ctx.t_requires_grad\n",
    "\n",
    "            t, y, *adjoint_params = ctx.saved_tensors\n",
    "            adjoint_params = tuple(adjoint_params)\n",
    "\n",
    "            # Backprop as if integrating up to event time.\n",
    "            # Does NOT backpropagate through the event time.\n",
    "            event_mode = ctx.event_mode\n",
    "            if event_mode:\n",
    "                event_t = ctx.event_t\n",
    "                _t = t\n",
    "                t = torch.cat([t[0].reshape(-1), event_t.reshape(-1)])\n",
    "                grad_y = grad_y[1]\n",
    "            else:\n",
    "                grad_y = grad_y[0]\n",
    "\n",
    "            ##################################\n",
    "            #      Set up initial state      #\n",
    "            ##################################\n",
    "\n",
    "            # [-1] because y and grad_y are both of shape (len(t), *y0.shape)\n",
    "            aug_state = [torch.zeros((), dtype=y.dtype, device=y.device), y[-1], grad_y[-1]]  # vjp_t, y, vjp_y\n",
    "            aug_state.extend([torch.zeros_like(param) for param in adjoint_params])  # vjp_params\n",
    "\n",
    "            ##################################\n",
    "            #    Set up backward ODE func    #\n",
    "            ##################################\n",
    "\n",
    "            # TODO: use a nn.Module and call odeint_adjoint to implement higher order derivatives.\n",
    "            def augmented_dynamics(t, y_aug):\n",
    "                # Dynamics of the original system augmented with\n",
    "                # the adjoint wrt y, and an integrator wrt t and args.\n",
    "                y = y_aug[1]\n",
    "                adj_y = y_aug[2]\n",
    "                # ignore gradients wrt time and parameters\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    t_ = t.detach()\n",
    "                    t = t_.requires_grad_(True)\n",
    "                    y = y.detach().requires_grad_(True)\n",
    "\n",
    "                    # If using an adaptive solver we don't want to waste time resolving dL/dt unless we need it (which\n",
    "                    # doesn't necessarily even exist if there is piecewise structure in time), so turning off gradients\n",
    "                    # wrt t here means we won't compute that if we don't need it.\n",
    "                    func_eval = func(t if t_requires_grad else t_, y)\n",
    "\n",
    "                    # Workaround for PyTorch bug #39784\n",
    "                    _t = torch.as_strided(t, (), ())  # noqa\n",
    "                    _y = torch.as_strided(y, (), ())  # noqa\n",
    "                    _params = tuple(torch.as_strided(param, (), ()) for param in adjoint_params)  # noqa\n",
    "\n",
    "                    vjp_t, vjp_y, *vjp_params = torch.autograd.grad(\n",
    "                        func_eval, (t, y) + adjoint_params, -adj_y,\n",
    "                        allow_unused=True, retain_graph=True\n",
    "                    )\n",
    "\n",
    "                # autograd.grad returns None if no gradient, set to zero.\n",
    "                vjp_t = torch.zeros_like(t) if vjp_t is None else vjp_t\n",
    "                vjp_y = torch.zeros_like(y) if vjp_y is None else vjp_y\n",
    "                vjp_params = [torch.zeros_like(param) if vjp_param is None else vjp_param\n",
    "                              for param, vjp_param in zip(adjoint_params, vjp_params)]\n",
    "\n",
    "                return (vjp_t, func_eval, vjp_y, *vjp_params)\n",
    "\n",
    "            ##################################\n",
    "            #       Solve adjoint ODE        #\n",
    "            ##################################\n",
    "\n",
    "            if t_requires_grad:\n",
    "                time_vjps = torch.empty(len(t), dtype=t.dtype, device=t.device)\n",
    "            else:\n",
    "                time_vjps = None\n",
    "            for i in range(len(t) - 1, 0, -1):\n",
    "                if t_requires_grad:\n",
    "                    # Compute the effect of moving the current time measurement point.\n",
    "                    # We don't compute this unless we need to, to save some computation.\n",
    "                    func_eval = func(t[i], y[i])\n",
    "                    dLd_cur_t = func_eval.reshape(-1).dot(grad_y[i].reshape(-1))\n",
    "                    aug_state[0] -= dLd_cur_t\n",
    "                    time_vjps[i] = dLd_cur_t\n",
    "\n",
    "                # Run the augmented system backwards in time.\n",
    "                aug_state = odeint(\n",
    "                    augmented_dynamics, tuple(aug_state),\n",
    "                    t[i - 1:i + 1].flip(0),\n",
    "                    rtol=adjoint_rtol, atol=adjoint_atol, method=adjoint_method, options=adjoint_options\n",
    "                )\n",
    "                aug_state = [a[1] for a in aug_state]  # extract just the t[i - 1] value\n",
    "                aug_state[1] = y[i - 1]  # update to use our forward-pass estimate of the state\n",
    "                aug_state[2] += grad_y[i - 1]  # update any gradients wrt state at this time point\n",
    "\n",
    "            if t_requires_grad:\n",
    "                time_vjps[0] = aug_state[0]\n",
    "\n",
    "            # Only compute gradient wrt initial time when in event handling mode.\n",
    "            if event_mode and t_requires_grad:\n",
    "                time_vjps = torch.cat([time_vjps[0].reshape(-1), torch.zeros_like(_t[1:])])\n",
    "\n",
    "            adj_y = aug_state[2]\n",
    "            adj_params = aug_state[3:]\n",
    "\n",
    "        return (None, None, adj_y, time_vjps, None, None, None, None, None, None, None, None, None, None, *adj_params)\n",
    "\n",
    "\n",
    "def odeint_adjoint(func, y0, t, *, rtol=1e-7, atol=1e-9, method=None, options=None, event_fn=None,\n",
    "                   adjoint_rtol=None, adjoint_atol=None, adjoint_method=None, adjoint_options=None, adjoint_params=None):\n",
    "\n",
    "    # We need this in order to access the variables inside this module,\n",
    "    # since we have no other way of getting variables along the execution path.\n",
    "    if adjoint_params is None and not isinstance(func, nn.Module):\n",
    "        raise ValueError('func must be an instance of nn.Module to specify the adjoint parameters; alternatively they '\n",
    "                         'can be specified explicitly via the `adjoint_params` argument. If there are no parameters '\n",
    "                         'then it is allowable to set `adjoint_params=()`.')\n",
    "\n",
    "    # Must come before _check_inputs as we don't want to use normalised input (in particular any changes to options)\n",
    "    if adjoint_rtol is None:\n",
    "        adjoint_rtol = rtol\n",
    "    if adjoint_atol is None:\n",
    "        adjoint_atol = atol\n",
    "    if adjoint_method is None:\n",
    "        adjoint_method = method\n",
    "\n",
    "    if adjoint_method != method and options is not None and adjoint_options is None:\n",
    "        raise ValueError(\"If `adjoint_method != method` then we cannot infer `adjoint_options` from `options`. So as \"\n",
    "                         \"`options` has been passed then `adjoint_options` must be passed as well.\")\n",
    "\n",
    "    if adjoint_options is None:\n",
    "        adjoint_options = {k: v for k, v in options.items() if k != \"norm\"} if options is not None else {}\n",
    "    else:\n",
    "        # Avoid in-place modifying a user-specified dict.\n",
    "        adjoint_options = adjoint_options.copy()\n",
    "\n",
    "    if adjoint_params is None:\n",
    "        adjoint_params = tuple(find_parameters(func))\n",
    "    else:\n",
    "        adjoint_params = tuple(adjoint_params)  # in case adjoint_params is a generator.\n",
    "\n",
    "    # Filter params that don't require gradients.\n",
    "    oldlen_ = len(adjoint_params)\n",
    "    adjoint_params = tuple(p for p in adjoint_params if p.requires_grad)\n",
    "    if len(adjoint_params) != oldlen_:\n",
    "        # Some params were excluded.\n",
    "        # Issue a warning if a user-specified norm is specified.\n",
    "        if 'norm' in adjoint_options and callable(adjoint_options['norm']):\n",
    "            warnings.warn(\"An adjoint parameter was passed without requiring gradient. For efficiency this will be \"\n",
    "                          \"excluded from the adjoint pass, and will not appear as a tensor in the adjoint norm.\")\n",
    "\n",
    "    # Convert to flattened state.\n",
    "    shapes, func, y0, t, rtol, atol, method, options, event_fn, decreasing_time = _check_inputs(func, y0, t, rtol, atol, method, options, event_fn, SOLVERS)\n",
    "\n",
    "    # Handle the adjoint norm function.\n",
    "    state_norm = options[\"norm\"]\n",
    "    handle_adjoint_norm_(adjoint_options, shapes, state_norm)\n",
    "\n",
    "    ans = OdeintAdjointMethod.apply(shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol,\n",
    "                                    adjoint_method, adjoint_options, t.requires_grad, *adjoint_params)\n",
    "\n",
    "    if event_fn is None:\n",
    "        solution = ans\n",
    "    else:\n",
    "        event_t, solution = ans\n",
    "        event_t = event_t.to(t)\n",
    "        if decreasing_time:\n",
    "            event_t = -event_t\n",
    "\n",
    "    if shapes is not None:\n",
    "        solution = _flat_to_shape(solution, (len(t),), shapes)\n",
    "\n",
    "    if event_fn is None:\n",
    "        return solution\n",
    "    else:\n",
    "        return event_t, solution\n",
    "\n",
    "\n",
    "def find_parameters(module):\n",
    "\n",
    "    assert isinstance(module, nn.Module)\n",
    "\n",
    "    # If called within DataParallel, parameters won't appear in module.parameters().\n",
    "    if getattr(module, '_is_replica', False):\n",
    "\n",
    "        def find_tensor_attributes(module):\n",
    "            tuples = [(k, v) for k, v in module.__dict__.items() if torch.is_tensor(v) and v.requires_grad]\n",
    "            return tuples\n",
    "\n",
    "        gen = module._named_members(get_members_fn=find_tensor_attributes)\n",
    "        return [param for _, param in gen]\n",
    "    else:\n",
    "        return list(module.parameters())\n",
    "\n",
    "\n",
    "def handle_adjoint_norm_(adjoint_options, shapes, state_norm):\n",
    "    \"\"\"In-place modifies the adjoint options to choose or wrap the norm function.\"\"\"\n",
    "\n",
    "    # This is the default adjoint norm on the backward pass: a mixed norm over the tuple of inputs.\n",
    "    def default_adjoint_norm(tensor_tuple):\n",
    "        t, y, adj_y, *adj_params = tensor_tuple\n",
    "        # (If the state is actually a flattened tuple then this will be unpacked again in state_norm.)\n",
    "        return max(t.abs(), state_norm(y), state_norm(adj_y), _mixed_norm(adj_params))\n",
    "\n",
    "    if \"norm\" not in adjoint_options:\n",
    "        # `adjoint_options` was not explicitly specified by the user. Use the default norm.\n",
    "        adjoint_options[\"norm\"] = default_adjoint_norm\n",
    "    else:\n",
    "        # `adjoint_options` was explicitly specified by the user...\n",
    "        try:\n",
    "            adjoint_norm = adjoint_options['norm']\n",
    "        except KeyError:\n",
    "            # ...but they did not specify the norm argument. Back to plan A: use the default norm.\n",
    "            adjoint_options['norm'] = default_adjoint_norm\n",
    "        else:\n",
    "            # ...and they did specify the norm argument.\n",
    "            if adjoint_norm == 'seminorm':\n",
    "                # They told us they want to use seminorms. Slight modification to plan A: use the default norm,\n",
    "                # but ignore the parameter state\n",
    "                def adjoint_seminorm(tensor_tuple):\n",
    "                    t, y, adj_y, *adj_params = tensor_tuple\n",
    "                    # (If the state is actually a flattened tuple then this will be unpacked again in state_norm.)\n",
    "                    return max(t.abs(), state_norm(y), state_norm(adj_y))\n",
    "                adjoint_options['norm'] = adjoint_seminorm\n",
    "            else:\n",
    "                # And they're using their own custom norm.\n",
    "                if shapes is None:\n",
    "                    # The state on the forward pass was a tensor, not a tuple. We don't need to do anything, they're\n",
    "                    # already going to get given the full adjoint state as (t, y, adj_y, adj_params)\n",
    "                    pass  # this branch included for clarity\n",
    "                else:\n",
    "                    # This is the bit that is tuple/tensor abstraction-breaking, because the odeint machinery\n",
    "                    # doesn't know about the tupled nature of the forward state. We need to tell the user's adjoint\n",
    "                    # norm about that ourselves.\n",
    "\n",
    "                    def _adjoint_norm(tensor_tuple):\n",
    "                        t, y, adj_y, *adj_params = tensor_tuple\n",
    "                        y = _flat_to_shape(y, (), shapes)\n",
    "                        adj_y = _flat_to_shape(adj_y, (), shapes)\n",
    "                        return adjoint_norm((t, *y, *adj_y, *adj_params))\n",
    "                    adjoint_options['norm'] = _adjoint_norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flow of Selecting ODE Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](figures/flow_ode_solver.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "Number of parameters: 576778\n",
    "    \n",
    "[ResBlock(64, 64) for _ in range(6)]\n",
    "```\n",
    "\n",
    "```python\n",
    "Number of parameters: 1908490 (= 576778 x 3.3)\n",
    "\n",
    "[ResBlock(64, 64) for _ in range(24)]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ODENet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Number of parameters: 208266\n",
    "    \n",
    "class ODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(ODEfunc, self).__init__()\n",
    "        self.norm1 = norm(dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm2 = norm(dim)\n",
    "        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm3 = norm(dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.norm1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(t, out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(t, out)\n",
    "        out = self.norm3(out)\n",
    "        return out\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "Number of parameters: 509322 (208266 x 2.2..)\n",
    "    \n",
    "class ODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(ODEfunc, self).__init__()\n",
    "        self.norm1 = norm(dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm2 = norm(dim)\n",
    "        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm3 = norm(dim)\n",
    "        \n",
    "        # debug (four times..)\n",
    "        self.conv3 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm4 = norm(dim)\n",
    "        self.conv4 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm5 = norm(dim)\n",
    "        self.conv5 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm6 = norm(dim)\n",
    "        self.conv6 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm7 = norm(dim)\n",
    "        self.conv8 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm9 = norm(dim)\n",
    "        self.conv9 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm10 = norm(dim)\n",
    "        self.conv11 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm12 = norm(dim)\n",
    "        self.conv12 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm13 = norm(dim)\n",
    "        \n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.norm1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(t, out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(t, out)\n",
    "        out = self.norm3(out)\n",
    "\n",
    "        return out\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
